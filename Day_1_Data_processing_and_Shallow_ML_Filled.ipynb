{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ya0CGr6LlIJT"
      },
      "source": [
        "# PARENT/AI-4-NICU Training School Hands-On Workshops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSb3RoTClb3B"
      },
      "source": [
        "\n",
        "## Lab 1. Introduction to data manipulation and processing with Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HD-VivePxEW_"
      },
      "source": [
        "Let's first introduce our working environment. Welcome to Google Colab. It's a fork of an open-source project called jupyter notebook, which is a software that allows for creating interactive notebooks(projects that conveniently interlace text content and text descriptions). As soon as we attempt to execute a code cell we're connected to a virtual machine in Google's cloud environment.\n",
        "\n",
        "Today we're going to be working on the dataset available [HERE](https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCQGJEoBEUBj"
      },
      "source": [
        "1. Let's try to download the mentioned dataset using the `wget` tool available in most Linux distributions. Example usage could be as follows:\n",
        "```bash\n",
        "!wget -O dataset.zip <DATASET_URL>\n",
        "```\n",
        "This command will download the file from the provided url and place it into the destination pointed by the `-O` option. You may have noticed that the command is predecessed by an exclamation mark. It's used to destinguish the shell commands executed directly on the machine from the python code lines."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVssw76DjVBV"
      },
      "outputs": [],
      "source": [
        "# TODO: Download the mentioned dataset to the colab's machine\n",
        "!wget -O dataset.zip https://archive.ics.uci.edu/static/public/17/breast+cancer+wisconsin+diagnostic.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfaqj4TpGQDU"
      },
      "source": [
        "2. The dataset is distributed in the form of a compressed `.zip` file. Before starting the work on the data we need to extract it. The `unzip` package should be a perfect fit for that. To extract the contents to the working directory we can just run:\n",
        "```bash\n",
        "!unzip <ARCHIVE_PATH>\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HnGT63MtjurE"
      },
      "outputs": [],
      "source": [
        "# TODO: Uzip the dataset\n",
        "!unzip dataset.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5d3JjGwHZq_"
      },
      "source": [
        "3. Our archive contained two files `wdbc.data` and `wdbc.names`. Let's peek into both of them and try to understand their contents. There are two commands that may come in handy in this kind of situations:\n",
        "  - `cat <FILE_PATH>` - prints the whole file to the console\n",
        "  - `head <FILE_PATH>` - prints few first lines (the number can be defined by the `-n` option)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9NDFPIwdkMJB"
      },
      "outputs": [],
      "source": [
        "# TODO: View contents of the wdbc.names file\n",
        "!cat wdbc.names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwjiAgYzkXxS"
      },
      "outputs": [],
      "source": [
        "# TODO: Print the first line of the dataset\n",
        "!head wdbc.data -n 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ME_0jf3vJJfo"
      },
      "source": [
        "4. Now that we understand the structure of the dataset we can \"read\" it (import it to our script), but before that we need to import [pandas](https://pandas.pydata.org/) library, which is one of the most popular data analysis and manipulation library for python."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsKZGfFSkme9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptK2QwgVLPe8"
      },
      "source": [
        "5. We can use a convenient `read_csv` method ([DOCS](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)) available in the pandas package to read the file in the CSV format and convert it to the dataframe tabular format implemented in pandas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M38uzKj7oCts"
      },
      "outputs": [],
      "source": [
        "# TODO: Import the dataset to dataframe format with a use of read_csv method\n",
        "data = pd.read_csv(\"wdbc.data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaQm8D9LeRLU"
      },
      "source": [
        "6. To view and examine the data we can call the following methods on the dataframe:\n",
        "- `.head()`\n",
        "- `.tail()`\n",
        "- `.describe()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mT_nMchgeiLp"
      },
      "outputs": [],
      "source": [
        "# TODO: Use the .head() method to view the first 10 lines in the dataset\n",
        "data.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7ekSs1SeyPG"
      },
      "source": [
        "7. You've probably noticed that the first row of the data was used as the columns labels. It's not ideal. Let's fix that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DYrlG3cvk9yq"
      },
      "outputs": [],
      "source": [
        "FEATURE_NAMES = [\"Radius\", \"Texture\", \"Perimeter\", \"Area\", \"Smoothness\", \"Compactness\", \"Concavity\", \"Concave points\", \"Symmetry\", \"Fractal dimension\"]\n",
        "FEATURE_STATISTICS = [\"MEAN\", \"SE\", \"WORST\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L21wVpAWKtM8"
      },
      "outputs": [],
      "source": [
        "# The code below assembles the list of the dataset columns.\n",
        "\n",
        "FEATURES = []\n",
        "\n",
        "for feature_name in FEATURE_NAMES:\n",
        "  for statistic in FEATURE_STATISTICS:\n",
        "    FEATURES.append(f\"{feature_name} {statistic}\")\n",
        "\n",
        "# and prints it\n",
        "print(FEATURES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3pefrn_UdxVA"
      },
      "outputs": [],
      "source": [
        "# TODO: Read the dataset properly - utilising the computed columns' names\n",
        "data = pd.read_csv(\"wdbc.data\", names=[\"ID\", \"Diagnosis\"] + FEATURES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGwp3MmmmB7Z"
      },
      "outputs": [],
      "source": [
        "# TODO: View the first 10 lines in the properly imported dataset\n",
        "data.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMi8d6MisIRp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48011a15-47c2-43fe-8462-0e698355af75"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Diagnosis\n",
              "B    357\n",
              "M    212\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ],
      "source": [
        "# TODO: Test the .describe() method of the dataframe\n",
        "data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['Diagnosis'].value_counts()"
      ],
      "metadata": {
        "id": "ihbEul45iyU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-tdZyqsfd4Q"
      },
      "source": [
        "8. Now that our data was succesfully imported and labeled let's perform some aggregations to get insights about it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MiAoyXw9fdFa"
      },
      "outputs": [],
      "source": [
        "# TODO: Filter just the malignant records\n",
        "data[data[\"Diagnosis\"] == 'M']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.query(\"Diagnosis == 'M'\")"
      ],
      "metadata": {
        "id": "YnBzylQ20E9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88NU2nvNgvw6"
      },
      "outputs": [],
      "source": [
        "# TODO: Get the number of malignant records\n",
        "data[data[\"Diagnosis\"] == 'M'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZvGBHGzjLkY"
      },
      "outputs": [],
      "source": [
        "# TODO: Display the records with mean radius greater than 25\n",
        "data[data[\"Radius MEAN\"] > 25]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H030jG5DkYBx"
      },
      "outputs": [],
      "source": [
        "# TODO: Display the records with mean radius greater than 25\n",
        "data[(data[\"Radius MEAN\"] > 25) & (data[\"Radius MEAN\"] < 28)]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.query(\"`Radius MEAN` > 25 and `Radius MEAN` < 28\")"
      ],
      "metadata": {
        "id": "3NLxRUj-0sN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-1aKvNdkkih"
      },
      "outputs": [],
      "source": [
        "# TODO: Display five top records in terms of the mean radius\n",
        "data.sort_values([\"Radius MEAN\"], ascending=False).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXS9V1RDhDYQ"
      },
      "outputs": [],
      "source": [
        "# TODO: Present the distribution of malignant and benign records depending on the mean radius\n",
        "data.groupby([data[\"Radius MEAN\"].astype(int), data[\"Diagnosis\"]]).agg({\"Diagnosis\": \"count\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JrOk4RyxEXL"
      },
      "outputs": [],
      "source": [
        "# TODO: Save results of your aggregations to a file\n",
        "data.sort_values([\"Radius MEAN\"], ascending=False).head().to_csv(\"top_5_by_mean_radius.csv\", sep=\";\")\n",
        "data.sort_values([\"Radius MEAN\"], ascending=False).head().to_excel(\"top_5_by_mean_radius.xlsx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCI_pzZqlkZ_"
      },
      "source": [
        "## Lab 2. Shallow machine learning methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6KjqOzPmhXz"
      },
      "source": [
        "1. Let's take a look at the data that we have available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MA_CUtJmczc"
      },
      "outputs": [],
      "source": [
        "# TODO: Display the dataset columns\n",
        "data.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CURp_j59m04f"
      },
      "source": [
        "2. Since we're provided with the labeled dataset the first thing that comes to mind is training a model that would process the rest of the columns and predict the label. We'll implement such models and learn how to measure their performance. All of that with the help of [scikitlearn](https://scikit-learn.org/stable/) library. The interface of the machine learning models available in the library requires us to split the data into two distinct parts: the input data a.k.a. features and the expected output of the model a.k.a. labels. It's a custom to name those x and y respectively, as the models essentialy are transformations(functions) that convert x -> y."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPo9H-wqo2HO"
      },
      "outputs": [],
      "source": [
        "# TODO: Prepare the features set\n",
        "x = data.drop(['ID', 'Diagnosis'], axis=1)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z24Tjr0so6Qk"
      },
      "outputs": [],
      "source": [
        "# TODO: Prepare the labels set\n",
        "y = data[['Diagnosis']] == 'M'\n",
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-wnvJpnpE4c"
      },
      "source": [
        "3. We're now almost ready to train a model, but we still miss one important detail, which is splitting the dataset into the training and test sets. Doing that is the only way to ensure a fair performance measurement, and avoiding the model overfitting. We'll use the [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) method available in scikitlearn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VwcVVgiQyXMC"
      },
      "outputs": [],
      "source": [
        "# TODO: Prepare training and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Verify the classes distribution in both sets\n",
        "print(y_train.groupby(\"Diagnosis\").agg({\"Diagnosis\":\"count\"}))"
      ],
      "metadata": {
        "id": "vC9uVWsm44n4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test.groupby(\"Diagnosis\").agg({\"Diagnosis\":\"count\"}))"
      ],
      "metadata": {
        "id": "3X9vT3Mt5Iwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrLVpfCArJtO"
      },
      "source": [
        "4. Now that our data is prepared, let's see it in action. We'll start by training a simple decision tree model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2RXAldQsJ1A"
      },
      "outputs": [],
      "source": [
        "# TODO: Train a decision tree clasifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(x_train, y_train.values.ravel())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39MzGEYzCOKk"
      },
      "source": [
        "5. The model was trained, so what do we do now? We need to somehow evaluate its performance. There is a plenty of ways and different metrics that we can use. We'll start with a so called confussion matrix which will show us what kind of mistakes does our model make."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCHgDScowhpY"
      },
      "outputs": [],
      "source": [
        "# TODO: Predict the labels for the records in test set\n",
        "predicted = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cuWdt8R7wdcs"
      },
      "outputs": [],
      "source": [
        "# TODO: Compute and display the confusion matrix\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "cm = confusion_matrix(y_test, predicted)\n",
        "\n",
        "print(cm)\n",
        "ConfusionMatrixDisplay(confusion_matrix=cm).plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSBovatsxf3K"
      },
      "source": [
        "6. Scikitlearn provides the whole framework for calculating the models' metrics. It provides it in a form of [classification_report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html#classification-report) method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgiEkdId4PM5"
      },
      "outputs": [],
      "source": [
        "# TODO: Compute and display the classification metrics\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "predicted = model.predict(x_test)\n",
        "\n",
        "print(classification_report(y_test, predicted))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ce0GGZCfskRa"
      },
      "outputs": [],
      "source": [
        "# TODO: Discover the insights of a decision tree\n",
        "from sklearn.tree import plot_tree\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(25, 10))\n",
        "plot_tree(model, fontsize=11, feature_names=x.columns)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3NpDWlNvS66"
      },
      "source": [
        "7. Let's now paralelly train multiple classifier trees and ellect the most probable label. That kind of architecture is called a random forest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7sjrc5B2ivz"
      },
      "outputs": [],
      "source": [
        "# TODO: Repeat the past steps with the random forest classifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=100)\n",
        "model.fit(x_train, y_train.values.ravel())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Etp3Gb9m3rt8"
      },
      "source": [
        "8. Let's now train a completely different model, a logistic-regression-based classifier, but before that we'll need to adjust our input data a bit, by performing scaling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YYrwzkZ3xRn"
      },
      "outputs": [],
      "source": [
        "# TODO: Use the StandardScaler provided by scikitlearn to transform the train and test features sets.\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "\n",
        "x_train_scaled = sc.fit_transform(x_train)\n",
        "x_test_scaled = sc.transform(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBBRs3tJ6Pjz"
      },
      "outputs": [],
      "source": [
        "# TODO: Train the LogisticRegression model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(x_train_scaled, y_train.values.ravel())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_lYvl4Ay4ww"
      },
      "outputs": [],
      "source": [
        "# TODO: Study the classification report\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "predicted = model.predict(x_test_scaled)\n",
        "\n",
        "print(classification_report(y_test, predicted))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(zip(x_train.columns, model.coef_[0]))"
      ],
      "metadata": {
        "id": "smKuQEa4b3gx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Overfitting"
      ],
      "metadata": {
        "id": "vw9-Gmu9Km-y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "benign = data[data[\"Diagnosis\"] == 'B']\n",
        "malignant = data[data[\"Diagnosis\"] == 'M'].head(10)\n",
        "\n",
        "data_filtered = pd.concat([benign, malignant])"
      ],
      "metadata": {
        "id": "zBts1hDHKNLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzlMhC5pMR_u"
      },
      "outputs": [],
      "source": [
        "x = data_filtered.drop(['ID', 'Diagnosis'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqSnNKFaMh7T"
      },
      "outputs": [],
      "source": [
        "y = data_filtered[['Diagnosis']] == 'M'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f86fallxMvb_"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHZIj3a9Mz6f"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "\n",
        "x_train_scaled = sc.fit_transform(x_train)\n",
        "x_test_scaled = sc.transform(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1nXggAtTM4SP"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Try setting the max_iter argument to a very low number.\n",
        "# This should cause a model not to converge and therefore we'll observe an even more significant overfitting.\n",
        "model = LogisticRegression(random_state=2)\n",
        "model.fit(x_train_scaled, y_train.values.ravel())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDqY2JAuM7Z5"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "predicted = model.predict(x_test_scaled)\n",
        "\n",
        "print(classification_report(y_test, predicted))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = model.predict(x_train_scaled)\n",
        "\n",
        "print(classification_report(y_train, predicted))"
      ],
      "metadata": {
        "id": "ezBJkekMKlf2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}